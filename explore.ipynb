{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a204cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb1f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of videos: 700\n",
      "Number of videos longer than 15 minutes: 117\n",
      "Min: {'video_id': 'P24_07', 'duration': '911.477233', 'fps': '59.9400599400599', 'resolution': '1920x1080'}\n",
      "Max: {'video_id': 'P01_109', 'duration': '3708.04', 'fps': '50.0', 'resolution': '1920x1080'}\n",
      "Mean: 1613.6855396752135\n",
      "Median: 1444.278483\n"
     ]
    }
   ],
   "source": [
    "video_info = csv.DictReader(open(\"EPIC_100_video_info.csv\"))\n",
    "video_info = list(video_info)\n",
    "\n",
    "videos_longer_than_15_minutes = [v for v in video_info if float(v[\"duration\"]) > 900]\n",
    "\n",
    "## Print min, max, mean, median, mode of video durations\n",
    "print(f\"Total number of videos: {len(video_info)}\")\n",
    "print(f\"Number of videos longer than 15 minutes: {len(videos_longer_than_15_minutes)}\")\n",
    "print(f\"Min: {min(videos_longer_than_15_minutes, key=lambda x: float(x['duration']))}\")\n",
    "print(f\"Max: {max(videos_longer_than_15_minutes, key=lambda x: float(x['duration']))}\")\n",
    "print(f\"Mean: {np.mean([float(v['duration']) for v in videos_longer_than_15_minutes])}\")\n",
    "print(f\"Median: {statistics.median(float(v['duration']) for v in videos_longer_than_15_minutes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f01117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "video_id = \"P24_07\"\n",
    "narration_low_level = []\n",
    "\n",
    "narration_low_level_files = [\"EPIC_100_train.csv\", \"EPIC_100_validation.csv\"]\n",
    "\n",
    "for file in narration_low_level_files:\n",
    "    narration_file = pd.read_csv(file)\n",
    "    narration_low_level.append(narration_file)\n",
    "\n",
    "narration_low_level_df = pd.concat(narration_low_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d320efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "narration_sentences = []\n",
    "\n",
    "narration_sentences_files = [\"retrieval_annotations/EPIC_100_retrieval_train_sentence.csv\", \"retrieval_annotations/EPIC_100_retrieval_test_sentence.csv\"]\n",
    "\n",
    "for file in narration_sentences_files:\n",
    "    narration_file = pd.read_csv(file)\n",
    "    narration_sentences.append(narration_file)\n",
    "\n",
    "narrations_sentences_df = pd.concat(narration_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_id = \"P37_101\"\n",
    "## Get video info for this video\n",
    "video_info = [v for v in video_info if v[\"video_id\"] == video_id]\n",
    "print(video_id, video_info)\n",
    "\n",
    "## Get visor annotations\n",
    "visor_annotations = pd.read_csv(\"visor_annotations/train/P37_101.json\")\n",
    "\n",
    "narrations_sentences_filtered = narrations_sentences_df[narrations_sentences_df[\"narration_id\"].str.startswith(video_id)]\n",
    "narrations_sentences_filtered = narrations_sentences_filtered.sort_values(\n",
    "    by=\"narration_id\",\n",
    "    key=lambda x: x.str.split(\"_\").str[-1].astype(int)\n",
    ")\n",
    "\n",
    "for _, row in narrations_sentences_filtered.iterrows():\n",
    "    narration_id = row[\"narration_id\"]\n",
    "    narration_phrase = row[\"narration\"]\n",
    "    nouns = row[\"nouns\"]\n",
    "    # Get the start_timestamp and stop_timestamp from narration_low_level_df for this narration_id\n",
    "    match = narration_low_level_df[narration_low_level_df[\"narration_id\"] == narration_id]\n",
    "    if not match.empty:\n",
    "        start_timestamp = match.iloc[0][\"start_timestamp\"]\n",
    "        stop_timestamp = match.iloc[0][\"stop_timestamp\"]\n",
    "    else:\n",
    "        start_timestamp = None\n",
    "        stop_timestamp = None\n",
    "    print(f\"narration_id: {narration_id}\")\n",
    "    print(f\"narration: {narration_phrase}\")\n",
    "    print(f\"nouns: {nouns}\")\n",
    "    print(f\"start_timestamp: {start_timestamp}\")\n",
    "    print(f\"stop_timestamp: {stop_timestamp}\")\n",
    "    print(\"------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af04228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Number of videos in EPIC-100: 700  -\n",
      "VISOR ONLY STATS\n",
      "Number of videos in VISOR: 158\n",
      "Overall median duration: 431.6435\n",
      "Number of videos longer than 15 minutes: 43\n",
      "Min: {'video_id': 'P02_109', 'duration': '912.58', 'fps': '50.0', 'resolution': '1920x1080'}\n",
      "Max: {'video_id': 'P01_09', 'duration': '3571.06815', 'fps': '59.9400599400599', 'resolution': '1920x1080'}\n",
      "Mean for videos longer than 15 minutes: 1699.820027139535\n",
      "Median for videos longer than 15 minutes: 1600.901617\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = [f for f in os.listdir(\"active_objects\") if f.endswith(\".json\")]\n",
    "video_ids_visor = [\"_\".join(f.split(\".\")[0].split(\"_\")[2:]) for f in files]\n",
    "\n",
    "video_info_ek100 = list(csv.DictReader(open(\"EPIC_100_video_info.csv\")))\n",
    "print(f\"  - Number of videos in EPIC-100: {len(video_info_ek100)}  -\")\n",
    "\n",
    "video_info_visor = list(v for v in video_info_ek100 if v[\"video_id\"] in video_ids_visor)\n",
    "visor_videos_longer_than_15_minutes = [v for v in video_info_visor if float(v[\"duration\"]) > 900]\n",
    "\n",
    "## Print min, max, mean, median, mode of video durations\n",
    "print(\"VISOR ONLY STATS\")\n",
    "print(f\"Number of videos in VISOR: {len(video_info_visor)}\")\n",
    "print(f\"Overall median duration: {statistics.median(float(v['duration']) for v in video_info_visor)}\")\n",
    "print(f\"Number of videos longer than 15 minutes: {len(visor_videos_longer_than_15_minutes)}\")\n",
    "print(f\"Min: {min(visor_videos_longer_than_15_minutes, key=lambda x: float(x['duration']))}\")\n",
    "print(f\"Max: {max(visor_videos_longer_than_15_minutes, key=lambda x: float(x['duration']))}\")\n",
    "print(f\"Mean for videos longer than 15 minutes: {np.mean([float(v['duration']) for v in visor_videos_longer_than_15_minutes])}\")\n",
    "print(f\"Median for videos longer than 15 minutes: {statistics.median(float(v['duration']) for v in visor_videos_longer_than_15_minutes)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
